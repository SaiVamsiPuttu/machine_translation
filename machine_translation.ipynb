{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaiVamsiPuttu/machine_translation/blob/main/machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUb_7Wfpbd8A"
      },
      "source": [
        "# Installing 'Transformer Architecture' and 'Indic Library'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7N7Fuiv4jXo",
        "outputId": "d9252d70-06d2-4eda-e1ee-1d709568c70c"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.3MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 22.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu36anLu6OHY",
        "outputId": "f365731e-65d3-41d4-ce7f-bee639739fb3"
      },
      "source": [
        "!pip install indic-nlp-library"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting indic-nlp-library\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/d4/495bb43b88a2a6d04b09c29fc5115f24872af74cd8317fe84026abd4ddb1/indic_nlp_library-0.81-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 2.2MB/s \n",
            "\u001b[?25hCollecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.1.5)\n",
            "Collecting sphinx-rtd-theme\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/24/2475e8f83519b54b2148d4a56eb1111f9cec630d088c3ffc214492c12107/sphinx_rtd_theme-0.5.2-py2.py3-none-any.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 4.3MB/s \n",
            "\u001b[?25hCollecting sphinx-argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/06/2b/dfad6a1831c3aeeae25d8d3d417224684befbf45e10c7f2141631616a6ed/sphinx-argparse-0.2.5.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2018.9)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (1.8.5)\n",
            "Collecting docutils<0.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/44/8a15e45ffa96e6cf82956dd8d7af9e666357e16b0d93b253903475ee947f/docutils-0.16-py2.py3-none-any.whl (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.23.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.6.1)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (57.0.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (1.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (2.11.3)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (1.2.4)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (0.7.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->indic-nlp-library) (20.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->sphinx-rtd-theme->indic-nlp-library) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx->sphinx-rtd-theme->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->sphinx-rtd-theme->indic-nlp-library) (1.1.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx->sphinx-rtd-theme->indic-nlp-library) (2.4.7)\n",
            "Building wheels for collected packages: sphinx-argparse\n",
            "  Building wheel for sphinx-argparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sphinx-argparse: filename=sphinx_argparse-0.2.5-cp37-none-any.whl size=11552 sha256=b053b8fde2c5494197ba9ddf13997b897c78792143b4d5f98ad02582e8429678\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/18/1b/4990a1859da4edc77ab312bc2986c08d2733fb5713d06e44f5\n",
            "Successfully built sphinx-argparse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: morfessor, docutils, sphinx-rtd-theme, sphinx-argparse, indic-nlp-library\n",
            "  Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "Successfully installed docutils-0.16 indic-nlp-library-0.81 morfessor-2.0.6 sphinx-argparse-0.2.5 sphinx-rtd-theme-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_LhcHzzbocP"
      },
      "source": [
        "# Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA0vo5Z-3ULz"
      },
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "import string\n",
        "import re\n",
        "from pickle import dump\n",
        "from unicodedata import normalize\n",
        "from numpy import array\n",
        "from indicnlp.normalize.indic_normalize import DevanagariNormalizer\n",
        "from indicnlp.tokenize import indic_tokenize  \n",
        "from numpy import argmax\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from pickle import load\n",
        "from numpy.random import rand\n",
        "from numpy.random import shuffle\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, CuDNNLSTM, CuDNNGRU, TimeDistributed, Flatten, Dropout, Bidirectional, RepeatVector\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from numpy import array, argmax\n",
        "from numpy.random import rand, shuffle\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
        "from tensorflow.keras.applications import Xception\n",
        "#import keras.utils.multi_gpu_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import scipy\n",
        "import statsmodels\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "from io import open\n",
        "import unicodedata\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import sys\n",
        "from unicodedata import normalize\n",
        "from numpy import array\n",
        "from pickle import dump, load\n",
        "from tensorflow.keras.layers import RepeatVector, TimeDistributed\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "INDIC_NLP_LIB_HOME=r\"anoopkunchukuttan-indic_nlp_library-eccde81/src\"\n",
        "INDIC_NLP_RESOURCES=r\"indic_nlp_resources-master\"\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
        "from indicnlp import loader\n",
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "from indicnlp.tokenize import indic_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdcQCAjiqTXM",
        "outputId": "d18a5780-58bf-447a-c041-0645d889b4cb"
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-4rpvDP645K"
      },
      "source": [
        "# Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLyyU_mz68fV"
      },
      "source": [
        "# Acquire Dataset\n",
        "malayalam = pd.read_fwf('/content/drive/MyDrive/NLP/Project/train.ml',columns='malayalam_text')\n",
        "telugu = pd.read_fwf('/content/drive/MyDrive/NLP/Project/train.te',columns=['telugu_text','extension1','extension2','extension3','extension4'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkv0mIrI4Uvg"
      },
      "source": [
        "telugu.columns = ['telugu_text','extension1','extension2','extension3','extension4']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etbl-hZD41l4"
      },
      "source": [
        "malayalam.columns = ['malayalam_text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eVCJek-J_T6"
      },
      "source": [
        "df_malayalam = malayalam['malayalam_text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAXENB7kXdaM"
      },
      "source": [
        "df_telugu = telugu['telugu_text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IMtK921Efd3"
      },
      "source": [
        "#df['sentence_length'] = df['Event'].str.split(\"/\").str.len()\n",
        "malayalam['sentence_length'] = malayalam['malayalam_text'].str.len()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbHHN2m4FexA"
      },
      "source": [
        "df = malayalam['sentence_length'].value_counts().rename_axis('length of sentence').reset_index(name='no of sentences')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "mal-YVe6FJkA",
        "outputId": "7164afa2-cab0-41dd-eaef-41d34b36e803"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "sentLength = df['length of sentence']\n",
        "noOfSent = df['no of sentences']\n",
        "ax.bar(sentLength,noOfSent)\n",
        "plt.title('Sentence length - no of such sentences in MALAYALAM dataset')\n",
        "plt.xlabel('Length of sentence')\n",
        "plt.ylabel('no of sentences')\n",
        "plt.savefig('/content/drive/MyDrive/NLP/Project/Dataset/mal_Sent_distr.png')\n",
        "plt.show()\n",
        "print(\"Max malayalam sentence length: \",df['length of sentence'].max())\n",
        "print(\"Min malayalam sentence length: \",df['length of sentence'].min())\n",
        "print(\"Mean malayalam sentence length: \",df['length of sentence'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFdCAYAAAD42+/rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df7wcVX3/8debhCC/EyCNkASCkqKRCkIKUailgBAQCX2IFKpNwBT8gRVa2xKUb0GUitYWpRU0SkyiVEQUiRCNIUCrtQGC/BIC5Rp+JBFIIJDwQ4HA5/vHOSvDsnvvJLlz75297+fjsY+dOXNm5pyd3f3sOXN2RhGBmZmZ1dNm/V0AMzMz23gO5GZmZjXmQG5mZlZjDuRmZmY15kBuZmZWYw7kZmZmNeZAbr1G0oOSDuuH/Y6TFJKG9vW+N5Wkz0p6XNKjfbS/GyX9dV/sq1NIekbSG/q7HINRnT/bfcmBvEKSDpL0C0lrJa2R9D+S/rgXtnuSpJ/3RhnrqL9+MPQ2SbsCnwAmRMTr+7s8faVuxy8itomIZRu6XiEI3daUvpOkFyQ92GKdGyU9KWmLpvTZkj7bw/5mS1ovaec8/5b83fOHTfkWSbqgin0W0s/NdT+9Kf30nH5ud9vdGJIOlrSit7fbX/vZEA7kFZG0HXAN8O/ADsBo4NPA8/1ZLhtQdgWeiIhV/V0Qq9RWkvYqzP8l8EBzJknjgD8BAjhmQ3YgaWvgvcBa4AMAEXE38EXgUknK+aaTvovOrWKfTf4PmNqUNi2nWy9yIK/OHwJExHci4qWI+G1E/DQi7mxkkPRBSUvzr+EFknYrLAtJH5Z0v6SnJH1FyZuBrwJvz11+T+X8W0j6oqSHJT0m6auStszLDpa0QtInJK2S9Iikkwv72lLSv0p6KP+C/3lh3Um5V+EpSXdIOrhM5SVtJmmGpF9LekLSFZJ2yMsaLZVpubyPS/pUU3nm5NdlqaR/bPwClvQtUgD8Ua7/PxZ2+/5W29tQjR6P/Ho+KekBSUcWlu8iaZ5SL0uXpFO62db2kuZKWp1f37Pza3MYsBDYJddjdot1d5J0TX7t10j6maTN8rKQtEch76taT5KmSLpd0rp8DCYXNr2bUu/Q05J+KmmnNmXvbv+7SPp+rtcDkj5eWO/cfLzn5n3cLWliXtby+HX3PlNqMX6mXZn1Ss/XU5KWSzopp3f3mWhbtxavw+9f6/w6f0XStbksN0l6Y6v1Cr5FCmANU4G5LfJNBRYDs5vyl/Fe4CngvKZ1LwC2BT4qaRTweeCDEfG7CvfZcAvpR8xbIPUQAK/L6S1JGpKP2eOSlgHvblp+cv5OeFrSMkkfyulbAz/mlc/TM/k9ur+k/83H+RFJ/yFpWF5Hki5U+k5cJ+ku5R9c7d477fazga9b74sIPyp4ANsBTwBzgCOBEU3LpwBdwJuBocDZwC8Ky4PUoh9O+uJbDUzOy04Cft60vQuBeaTW/7bAj4DP5WUHA+tJH7jNgaOA5xplAr4C3Ej6pT4EeAewRZ5/IuffDHhXnh/Zps4PAofl6dNJXxBj8ra+BnwnLxuX6/d1YEtgb1JPxZvz8guA/wJG5PXvBFa02k+Z7W3EsTsJeBE4Jb8eHwF+Aygv/2/gYtKX0j752BzSZltzgavzMRlHao1MLxyXFd2U43OkH22b58efFMoQwB6FvLOBz+bp/UmtpHfl4zYaeFNediPwa9IPzS3z/AUbsv+8zVuBfwKGAW8AlgFH5PXOBX6X3zdD8nYWd3P8un2fdVdmYDfgaeDEXMYdgX1KfCbavrYtXoffv9b5dX4iv8ZDgcuAy9usNy6vOw5Ynl+LCcC9wGHAg035u4CPAvuR3n+jWh3fNvtaBHwBGEX6rO9XWPY2YA3ph+OX+mif5wLfBj4JfD6nfQE4K6ef22abH86vz9h83G7Ir+HQvPzdwBtJ78M/JX2P7dvu85TrNSkfq3HAUuCMvOwI0vt4eN7em4GdS36ftv3c9sej3wvQyY/8xpgNrMhv9HmNDwrpV930Qt7N8ptytzwfwEGF5VcAM/L0SRQCeX4TPgu8sZD2duCBPH0w8NvGhyGnrcpv8M3ysr1blP9M4FtNaQuAaW3q+yCvBPKlwKGFZTvnL4rGByqAMYXlNwMn5OnfB4U8/9eUC+Qtt7cRx+0koKswv1Xe/utJXzAvAdsWln8OmN1iO0OAF0jnwBtpHwJuLByX7gL5eaQfAXu0WNZdIP8acGGbbd4InF2Y/yjwkw3ZP3AA8HBT2lnAN/P0ucB1hWUTgN92c/y6fZ91V+a836talL2nz0Tb17a71zq/zt8oLDsKuLfNeo335VDgOlLguAD4FE2BHDiI9PnYKc/fC/xtq+PbYj+7Ai/zyg+YBcCXm/L8C+l7aKu+2CevBPJdgYdJP5YeJn1+ugvk1wMfLswfTiGQt8j/Q+D0Mp+nnOeMxvsFOIT0w3oSsNkGvHd63E9fP9y1XqGIWBoRJ0XEGGAvYBfgS3nxbsCXc5fPU6RfzCK1ThqKI5mfA7Zps6uRpGBza2F7P8npDU9ExPoW29uJ1LL8dYvt7ga8r7HNvN2DSEG5J7sBVxXWW0oKgKNK1G8XUgumoTjdnR5fL0m7FrrEnimzrYh4Lk9uk8u2JiKeLuR9iFcft4adSF9gD5XI28q/kFpMP83diDNKrjeW1sezoez7qt3+dyN1LRbfF5+k+2P7OrUfeVzmfdauzO3q2tNnYmNf2+7K0p25pB+IJ5K62ptNA34aEY/n+f+kfFf3XwFLI+L2PH8Z8JeSNi/kuZv0w+G5QlrV+yQiHia9zv8M3B8RPX2Wmz/7xc8Oko6UtDifDnmK9EOq5amhnP8P8ymURyWty+XYKZfteuA/SD2SqyTNVBrbVOb7dEDxkP4+EhH3Kp0H/VBOWg6cHxGXbczmmuYfJ7Wq3xIRKzdwW4+TukHfCNzRtGw5qaXU9hxwN5aTzsX9T/MCpQE23XmE1KV+T54f27S8uf6l5S+WMl+87fwG2EHStoVgvivQ6nV/nNTi2Y1X6tIub6uyPk0a1f6JfO7uekm3RMQiUgDZqpD99aQWF6TXvqfzthu9/7z9ByJi/MZuuml+U99n+7dI7/Yz0cNrW4Xvk4LGrRHxsAojyfN5++OBIXrlb4hbAMMl7R0RzZ/LZlOBXQvrDiWdYjiK1OvwGn28z7nALOBkevYIr/6871oo8xak13EqcHVEvCjph6QGELT+XrgEuA04MSKelnQGcFxjYURcBFwk6Q9IvZ7/AJxD99+nG/39UxW3yCsi6U1Kg8vG5PmxpF/ji3OWrwJnFQaCbC/pfSU3/xgwpjFoIyJeJp0fvjC/IZE0WtIRPW0orzsL+Lc8OGSIpLfnD823gfdIOiKnv05p4NyYEmX8KnC+8gA+SSMlTSlZvytIr80ISaOBjzUtf4x0XrbP5RbFL4DP5dfjrcB00mvVnPclUl3Ol7Rtfi3+rlXeViQdLWkPSSKd836J1J0JcDupBTREaSDbnxZWvRQ4WdKhSgPrRkt604bWtZv93ww8LenMPABoiKS9VP6vlc3Hb1PeZ5cBh0k6XtJQSTtK2qenz0QPr22vi4hnSV25rf7Df2ze/wTSmIt9SKflfsarR303XpvGY5ikt5N+tO1fWHcvUuu6ecR4f+3zu6Qu8iu6KU/DFcDHJY2RNAIo9pQMI/3YWA2sVxqAenhh+WPAjpK2L6RtC6wDnsmfgY80Fkj6Y0kH5F6EZ0kNmpdLfJ+22k+/ciCvztOkc4k3SXqWFMB/RWoFEBFXkUaQXp67fH5FGhRXxvWkrrJHJTW6xc4kdWEtztu7Dtiz5Pb+HriLNJp0TS7XZjloTSF1m64mtX7+gXLvmy+TxgT8VNLTpPofULI855Falw/kelzJq/+29zng7Nzt9fclt9mbTiSd//wNcBVwTkRc1ybv35C+JJYBPyd92c0quZ/xpPo/A/wvcHFE3JCXnQ68hzRq+P2kc4UARMTNpNbPhaQg9V+kXoEN1XL/+QfK0aQv8AdIrd9vAGW/2F51/DblfZZ7WI4ifa7WkH7g7J0Xd/eZ6O61rURELImIVqcBppHGFzwcEY82HqQW/Pv1yimJGaSWYuNxfV736oi4q2ndLwNHK/9TpD/3GekfO9dFxG9LvExfJ51vvwP4JfCDwnaeBj5OCvZPkv7GN6+w/F7gO8Cy/N7ahfTd9pek7+Ovk35UNGyX054kdeE/QTrlAt28d9rsp181RsCaDViSPkIauPanPWY2Mxtk3CK3AUfSzpIOzN3Ce5JaW1f1d7nMzAYiD3azgWgY6S9Uu5O6ji8n/W/bzMyauGvdzMysxty1bmZmVmMO5GZmZjU26M6R77TTTjFu3Lj+LoaZmdkGufXWWx+PiNdcYW7QBfJx48axZMmS/i6GmZnZBpH0UKt0d62bmZnVmAO5mZlZjTmQm5mZ1ZgDuZmZWY05kJuZmdWYA7mZmVmNOZCbmZnVmAO5mZlZjTmQm5mZ1ZgDuZmZWY05kJuZmdWYA7mZmVmNOZCbmZn1onEzrmXcjGv7bH8O5GZmZjXmQG5mZlZjDuRmZmY15kBuZmZWYw7kZmZmNeZAbmZmVmMO5GZmZjXmQG5mZlZjDuRmZmY1Vmkgl/S3ku6W9CtJ35H0Okm7S7pJUpek70oalvNukee78vJxhe2cldPvk3REIX1yTuuSNKPKupiZmQ1ElQVySaOBjwMTI2IvYAhwAvB54MKI2AN4EpieV5kOPJnTL8z5kDQhr/cWYDJwsaQhkoYAXwGOBCYAJ+a8ZmZmg0bVXetDgS0lDQW2Ah4BDgGuzMvnAMfm6Sl5nrz8UEnK6ZdHxPMR8QDQBeyfH10RsSwiXgAuz3nNzMwGjcoCeUSsBL4IPEwK4GuBW4GnImJ9zrYCGJ2nRwPL87rrc/4di+lN67RLNzMzGzSq7FofQWoh7w7sAmxN6hrvc5JOlbRE0pLVq1f3RxHMzMwqUWXX+mHAAxGxOiJeBH4AHAgMz13tAGOAlXl6JTAWIC/fHniimN60Trv014iImRExMSImjhw5sjfqZmZmNiBUGcgfBiZJ2iqf6z4UuAe4ATgu55kGXJ2n5+V58vLrIyJy+gl5VPvuwHjgZuAWYHweBT+MNCBuXoX1MTMzG3CG9pxl40TETZKuBH4JrAduA2YC1wKXS/psTrs0r3Ip8C1JXcAaUmAmIu6WdAXpR8B64LSIeAlA0seABaQR8bMi4u6q6mNmZjYQVRbIASLiHOCcpuRlpBHnzXl/B7yvzXbOB85vkT4fmL/pJTUzM6snX9nNzMysxhzIzczMasyB3MzMrMYcyM3MzGrMgdzMzKzGHMjNzMxqzIHczMysxhzIzczMasyB3MzMrMYcyM3MzGrMgdzMzKzGHMjNzMxqzIHczMysxhzIzczMasyB3MzMrMYcyM3MzGrMgdzMzKzGHMjNzMxqzIHczMysxhzIzczMasyB3MzMrMYcyM3MzGrMgdzMzKzGHMjNzMxqrLJALmlPSbcXHusknSFpB0kLJd2fn0fk/JJ0kaQuSXdK2rewrWk5//2SphXS95N0V17nIkmqqj5mZmYDUWWBPCLui4h9ImIfYD/gOeAqYAawKCLGA4vyPMCRwPj8OBW4BEDSDsA5wAHA/sA5jeCf85xSWG9yVfUxMzMbiPqqa/1Q4NcR8RAwBZiT0+cAx+bpKcDcSBYDwyXtDBwBLIyINRHxJLAQmJyXbRcRiyMigLmFbZmZmQ0KfRXITwC+k6dHRcQjefpRYFSeHg0sL6yzIqd1l76iRfprSDpV0hJJS1avXr0p9TAzMxtQKg/kkoYBxwDfa16WW9JRdRkiYmZETIyIiSNHjqx6d2ZmZn2mL1rkRwK/jIjH8vxjuVuc/Lwqp68ExhbWG5PTuksf0yLdzMxs0OiLQH4ir3SrA8wDGiPPpwFXF9Kn5tHrk4C1uQt+AXC4pBF5kNvhwIK8bJ2kSXm0+tTCtszMzAaFoVVuXNLWwLuADxWSLwCukDQdeAg4PqfPB44Cukgj3E8GiIg1kj4D3JLznRcRa/L0R4HZwJbAj/PDzMxs0Kg0kEfEs8COTWlPkEaxN+cN4LQ225kFzGqRvgTYq1cKa2ZmVkO+spuZmVmNOZCbmZnVmAO5mZlZjTmQm5mZ1ZgDuZmZWY05kJuZmdWYA7mZmVmNOZCbmZnVmAO5mZlZjTmQm5mZ1ZgDuZmZWY05kJuZmdWYA7mZmVmNOZCbmZnVmAO5mZlZjTmQm5mZ1ZgDuZmZWY05kJuZmdWYA7mZmVmNOZCbmZnVmAO5mZlZjTmQm5mZ1ZgDuZmZWY1VGsglDZd0paR7JS2V9HZJO0haKOn+/Dwi55WkiyR1SbpT0r6F7UzL+e+XNK2Qvp+ku/I6F0lSlfUxMzMbaKpukX8Z+ElEvAnYG1gKzAAWRcR4YFGeBzgSGJ8fpwKXAEjaATgHOADYHzinEfxznlMK602uuD5mZmYDSmWBXNL2wDuBSwEi4oWIeAqYAszJ2eYAx+bpKcDcSBYDwyXtDBwBLIyINRHxJLAQmJyXbRcRiyMigLmFbZmZmQ0KVbbIdwdWA9+UdJukb0jaGhgVEY/kPI8Co/L0aGB5Yf0VOa279BUt0s3MzAaNKgP5UGBf4JKIeBvwLK90owOQW9JRYRkAkHSqpCWSlqxevbrq3ZmZmfWZKgP5CmBFRNyU568kBfbHcrc4+XlVXr4SGFtYf0xO6y59TIv014iImRExMSImjhw5cpMqZWZmNpBUFsgj4lFguaQ9c9KhwD3APKAx8nwacHWengdMzaPXJwFrcxf8AuBwSSPyILfDgQV52TpJk/Jo9amFbZmZmQ0KQyve/t8Al0kaBiwDTib9eLhC0nTgIeD4nHc+cBTQBTyX8xIRayR9Brgl5zsvItbk6Y8Cs4EtgR/nh5mZ2aBRaSCPiNuBiS0WHdoibwCntdnOLGBWi/QlwF6bWEwzM7Pa8pXdzMzMasyB3MzMrMYcyM3MzGrMgdzMzKzGHMjNzMxqzIHczMysxhzIzczMasyB3MzMrMZ6DOSS3idp2zx9tqQfSNq3+qKZmZlZT8q0yP9fRDwt6SDgMNL9xS+ptlhmZmZWRplA/lJ+fjcwMyKuBYZVVyQzMzMrq0wgXynpa8BfAPMlbVFyPTMzM6tYmYB8POlWokdExFPADsA/VFoqMzMzK6XHQB4RzwGrgINy0nrg/ioLZWZmZuWUGbV+DnAmcFZO2hz4dpWFMjMzs3LKdK3/OXAM8CxARPwG2LbKQpmZmVk5Q0vkeSEiQlIASNq64jLZADZuxrW/n37wgnf3Y0nMzAzKtcivyKPWh0s6BbgO+Hq1xTIzM7MyemyRR8QXJb0LWAfsCfxTRCysvGRmZmbWox4DuaTdgZ81grekLSWNi4gHqy6cmZmZda9M1/r3gJcL8y/lNOtw42Zc+6pz4mZmNvCUCeRDI+KFxkye9iVarRT/GDAzq1aZQL5a0jGNGUlTgMerK5L1JwdeM7N6KfP3sw8Dl0n6D0DAcmBqpaWyWvBf0czM+l+ZUeu/BiZJ2ibPP1N245IeBJ4mnVdfHxETJe0AfBcYBzwIHB8RT0oS8GXgKOA54KSI+GXezjTg7LzZz0bEnJy+HzAb2BKYD5weEVG2fJY0AnK7YFymhe6gbmbWP8qMWt8CeC8p8A5N8RYi4ryS+/iziCh2xc8AFkXEBZJm5PkzgSOB8flxAOme5wfkwH8OMBEI4FZJ8yLiyZznFOAmUiCfDPy4ZLmsIj39MDAzs95T5hz51cAU0s1Sni08NtYUYE6engMcW0ifG8li0gVodgaOABZGxJocvBcCk/Oy7SJicW6Fzy1sy3rgc+FmZp2hzDnyMRExeSO3H8BP8+VdvxYRM4FREfFIXv4oMCpPjyadf29YkdO6S1/RIv01JJ0KnAqw6667bmRVrCpuwZuZbbwyLfJfSPqjjdz+QRGxL6nb/DRJ7ywuzC3pys9pR8TMiJgYERNHjhxZ9e6sDfcCmJn1vjKB/CDSeen7JN0p6S5Jd5bZeESszM+rgKuA/YHHcrc4+XlVzr4SGFtYfUxO6y59TIt0qwEHdTOz3lEmkDcGoR0OvAc4Oj93S9LWkrZtTOf1fwXMA6blbNNI5+DJ6VOVTALW5i74BcDhkkZIGpG3syAvWydpUh7xPrWwLTMzs0GhzN/PHpJ0EDA+Ir4paSSwTYltjwKuyqPchwL/GRE/kXQL6Y5q04GHgONz/vmkv551kf5+dnLe/xpJnwFuyfnOi4g1efqjvPL3sx/jEetmZjbIlPn7WeOvX3sC3wQ2B74NHNjdehGxDNi7RfoTwKEt0gM4rc22ZgGzWqQvAfbqqQ5mZmadqkzX+p8Dx5D/chYRvwG2rbJQZmZmVk6ZQP5CcXR5Pt9tZmZmA0CZQH6FpK+RLtByCnAd8I1qi2VmZmZllBns9kVJ7wLWkc6T/1NELKy8ZNbrfOEVM7POU2aw2+cj4kzSpVGb08x6VfHHhn94mJn1rEzX+rtapB3Z2wUxMzOzDde2RS7pI6T/ab+h6Upu2wL/U3XBzMzMrGfdda3/J+kCK58j3Wq04enCBVnMzMysH7UN5BGxFlgLnChpCOlKbUOBbSRtExEP91EZzczMrI0yg90+BpwLPAa8nJMDeGt1xTIzM7MyytyP/Axgz3xpVbN+4RHsZmatlRm1vpzUxW5mZmYDTJkW+TLgRknXAs83EiPi3yorlVkbxXuYu3VuZlYukD+cH8Pyw8zMzAaIMpdo/TSApK0i4rnqi2RmZmZl9XiOXNLbJd0D3Jvn95Z0ceUlMzMzsx6V6Vr/EnAEMA8gIu6Q9M5KS2VWQvF8eZHPnZvZYFImkBMRyyUVk16qpjjW2wbj37Y8IM7MBpMygXy5pHcAIWlz4HRgabXFMjMzszLK/I/8w8BpwGhgJbBPnjczM7N+VmbU+uPA+/ugLNZLBmN3ejt+Lcys05UZtf4FSdtJ2lzSIkmrJX2gLwpnZmZm3SvTtX54RKwDjgYeBPYA/qHKQpmZmVk5ZQJ5o/v93cD38u1NS5M0RNJtkq7J87tLuklSl6TvShqW07fI8115+bjCNs7K6fdJOqKQPjmndUma0bxvMzOzTlcmkF8j6V5gP2CRpJHA7zZgH82j3D8PXBgRewBPAtNz+nTgyZx+Yc6HpAnACcBbgMnAxfnHwRDgK8CRwATSfdMnbEC5zMzMaq/HQB4RM4B3ABMj4kXgOWBKmY1LGkNqyX8jzws4BLgyZ5kDHJunp+R58vJDc/4pwOUR8XxEPAB0AfvnR1dELIuIF4DLy5bLzMysU5RpkRMRayLipTz9bEQ8WnL7XwL+EXg5z+8IPBUR6/P8CtLf2sjPy/M+1pNunbpjMb1pnXbpZi2Nm3Ft26vBmZnVValAvjEkHQ2siohbq9rHBpTlVElLJC1ZvXp1fxfHzMys17QN5JIOzM9bbOS2DwSOkfQgqdv7EODLwHBJjQF0Y0gXmSE/j837HApsDzxRTG9ap136a0TEzIiYGBETR44cuZHVsU7i1rmZdYruWuQX5ef/3ZgNR8RZETEmIsaRBqtdHxHvB24AjsvZpgFX5+l5eZ68/PqIiJx+Qh7VvjswHrgZuAUYn0fBD8v7mLcxZTUzM6ur7q7s9qKkmcBoSRc1L4yIj2/kPs8ELpf0WeA24NKcfinwLUldwBpSYCYi7pZ0BXAPsB44rXG+XtLHgAXAEGBWRNy9kWUyMzOrpe4C+dHAYaRbmG7See6IuBG4MU8vI404b87zO+B9bdY/Hzi/Rfp8YP6mlM3MzKzO2gbyfI31yyUtjYg7+rBMZn3K12M3szorM2r9CUlXSVqVH9/P/w83MzOzflYmkH+TNIhsl/z4UU4zMzOzflYmkP9BRHwzItbnx2zA/+EyMzMbAMoE8sclfaBxffN8C9Mnqi6YmZmZ9ay7UesNHwT+nXQjkwB+AZxcZaFsw/niJmZmg1OPgTwiHgKO6YOymJmZ2Qaq7FrrZmZmVj0HcrM2fD12M6sDB3IzM7Ma6zGQS9pe0oWN24BK+ldJ2/dF4cz6mlvhZlY3ZVrks4B1wPH5sQ5fEMbMzGxAKPP3szdGxHsL85+WdHtVBbLy3HI0M7MyLfLfSjqoMSPpQOC31RXJbOBxl7uZDVRlWuQfBubm8+Ii3Sv8pCoLZWZmZuWUuSDMHcDekrbL8+sqL5WZmZmV0mMgl7QF8F5gHDBUEgARcV6lJTMbgIrd675/uZkNBGW61q8G1gK3As9XWxwzMzPbEGUC+ZiImFx5Scw6hFvtZtaXyoxa/4WkP6q8JGZmZrbByrTIDwJOkvQAqWtdQETEWystmdkA55a3mQ0EZQL5kZWXwszMzDZK2fuR2wDhi5KYmVmR735mZmZWY5UFckmvk3SzpDsk3S3p0zl9d0k3SeqS9F1Jw3L6Fnm+Ky8fV9jWWTn9PklHFNIn57QuSTOqqouZmdlAVWWL/HngkIjYG9gHmCxpEvB54MKI2AN4Epie808HnszpF+Z8SJoAnAC8BZgMXCxpiKQhwFdI5/AnACfmvGZmZoNGmcFuGyUiAngmz26eHwEcAvxlTp8DnAtcAkzJ0wBXAv+hdBm5KcDlEfE88ICkLmD/nK8rIpYBSLo8572nqjqZteOxC2bWXyo9R55bzrcDq4CFwK+BpyJifc6yAhidp0cDywHy8rXAjsX0pnXapbcqx6mSlkhasnr16t6omlkpvmuamVWt0kAeES9FxD7AGFIr+k1V7q+bcsyMiIkRMXHkyJH9UQQzM7NK9Mmo9Yh4CrgBeDswXFKjS38MsDJPrwTGAuTl2wNPFNOb1mmXbmZmNmhUOWp9pKTheXpL4F3AUlJAPy5nm0a6KQvAvDxPXn59Ps8+Dzghj2rfHRgP3AzcAozPo+CHkQbEzauqPmabyt3sZlaFyga7ATsDc/Lo8s2AKyLiGkn3AJdL+ixwG3Bpzn8p8K08mG0NKTATEXdLuoI0iG09cFpEvAQg6WPAAmAIMCsi7q6wPmZmZgNOlaPW7wTe1iJ9Ga+MOi+m/w54X5ttnQ+c3yJ9PjB/kwtrZmZWU76ym5mZWY05kJuZmdWYA7lZP/DANzPrLQ7kZmZmNQga41oAAA8lSURBVOZAbmZmVmMO5GZmZjXmQG5mZlZjVV4QxnqJB0WZmVk7bpGb9TOPYDezTeFAblYDDvZm1o4DuZmZWY05kJsNUG6Fm1kZDuRmA4iDt5ltKAdyMzOzGnMgNzMzqzEHcjMzsxrzBWHMaqbVOfQHL3h3P5TEzAYCB/IBzIOezMysJ+5aNzMzqzEHcjMzsxpzIDczM6sxB3IzM7MacyA3MzOrscoCuaSxkm6QdI+kuyWdntN3kLRQ0v35eUROl6SLJHVJulPSvoVtTcv575c0rZC+n6S78joXSVJV9TEbyBqXdvU/HcwGnypb5OuBT0TEBGAScJqkCcAMYFFEjAcW5XmAI4Hx+XEqcAmkwA+cAxwA7A+c0wj+Oc8phfUmV1gfs1pwUDcbXCr7H3lEPAI8kqeflrQUGA1MAQ7O2eYANwJn5vS5ERHAYknDJe2c8y6MiDUAkhYCkyXdCGwXEYtz+lzgWODHVdXJrG588Rizztcn58gljQPeBtwEjMpBHuBRYFSeHg0sL6y2Iqd1l76iRbqZmdmgUXkgl7QN8H3gjIhYV1yWW9/RB2U4VdISSUtWr15d9e7MzMz6TKWBXNLmpCB+WUT8ICc/lrvMyc+rcvpKYGxh9TE5rbv0MS3SXyMiZkbExIiYOHLkyE2rlJmZ2QBS5ah1AZcCSyPi3wqL5gGNkefTgKsL6VPz6PVJwNrcBb8AOFzSiDzI7XBgQV62TtKkvK+phW2ZWTc8GM6sc1R505QDgb8C7pJ0e077JHABcIWk6cBDwPF52XzgKKALeA44GSAi1kj6DHBLzndeY+Ab8FFgNrAlaZCbB7qZmdmgUuWo9Z8D7f7XfWiL/AGc1mZbs4BZLdKXAHttQjHNzMxqzVd2MzMzqzEHcrNBrni+3OfOzerHgXyA8RepmZltCAdyMzOzGnMgN7OW3DtkVg8O5GZmZjXmQG5mG8QtdbOBxYHczHrk4G02cDmQm5mZ1ViVl2g1sw5WbKH7Hudm/cctcjMzsxpzIDczM6sxB3IzM7Ma8zlyM9tkPl9u1n/cIjczM6sxt8jNrDKt/nvuFrtZ73IgHwAaX3b+grNO4AvHmPUtd62bmZnVmAO5mZlZjTmQm1mf87XbzXqPA7mZmVmNOZCbWb8qts7bTZtZew7kZmZmNeZAbmYDnlvnZu1VFsglzZK0StKvCmk7SFoo6f78PCKnS9JFkrok3Slp38I603L++yVNK6TvJ+muvM5FklRVXczMzLrTnz82q2yRzwYmN6XNABZFxHhgUZ4HOBIYnx+nApdACvzAOcABwP7AOY3gn/OcUliveV9m1oHcOjd7tcoCeUT8N7CmKXkKMCdPzwGOLaTPjWQxMFzSzsARwMKIWBMRTwILgcl52XYRsTgiAphb2JaZmdmg0deXaB0VEY/k6UeBUXl6NLC8kG9FTusufUWL9JYknUpq6bPrrrtuQvF7jy/LatZ7yrTQ/VmzTtVv11qPiJAUfbSvmcBMgIkTJ/bJPs2sehvSxe5brVqn6utR64/lbnHy86qcvhIYW8g3Jqd1lz6mRbqZmdmg0teBfB7QGHk+Dbi6kD41j16fBKzNXfALgMMljciD3A4HFuRl6yRNyqPVpxa2ZWa2UTyQzuqosq51Sd8BDgZ2krSCNPr8AuAKSdOBh4Djc/b5wFFAF/AccDJARKyR9BnglpzvvIhoDKD7KGlk/JbAj/PDzKxHHqNinaSyQB4RJ7ZZdGiLvAGc1mY7s4BZLdKXAHttShnNzNpxsLe68JXdzGxQc3e61Z0DuZmZWY05kJuZ9aBdq92teRsIHMjNzDaAg7cNNA7kZmZmNdZvV3YzM+skPbXS241+9+h421RukZuZmdWYW+RmZn2gVYvdrXDrDW6Rm5kNEMWBdB5UZ2U5kJuZDXDtAryDvYG71s3MOopv1zr4OJCbmXWAdhesacUj6DuLu9bNzMxqzC1yM7NBpswI+mLrvN20DQxukZuZ2UbxwLuBwS1yMzPrVf7PfN9yIDczs8qVGXjnLvyN4651MzPrN2W65N2F3z23yPuQf2GamfWeDRmQ18n/r3cgNzOzjtSu5V7mTnXtGl4DsUHmrnUzM7NutOvOHyjd/A7kFRsoB9rMzDqTA7mZmVmN1T6QS5os6T5JXZJm9Hd5wK1wMzPrO7UO5JKGAF8BjgQmACdKmtC/pTIzM+s7dR+1vj/QFRHLACRdDkwB7umLnfvqRWZm1t9q3SIHRgPLC/MrcpqZmdmgoIjo7zJsNEnHAZMj4q/z/F8BB0TEx5rynQqcmmf3BO5rsbmdgMcrLO5A4Xp2nsFSV9ezswyWekLv1XW3iBjZnFj3rvWVwNjC/Jic9ioRMROY2d2GJC2JiIm9W7yBx/XsPIOlrq5nZxks9YTq61r3rvVbgPGSdpc0DDgBmNfPZTIzM+sztW6RR8R6SR8DFgBDgFkRcXc/F8vMzKzP1DqQA0TEfGB+L2yq2673DuJ6dp7BUlfXs7MMlnpCxXWt9WA3MzOzwa7u58jNzMwGtUEfyAfiJV57i6Sxkm6QdI+kuyWdntN3kLRQ0v35eUR/l7U3SBoi6TZJ1+T53SXdlI/td/OAyFqTNFzSlZLulbRU0ts78XhK+tv8nv2VpO9Iel2nHE9JsyStkvSrQlrLY6jkolznOyXt238l3zBt6vkv+b17p6SrJA0vLDsr1/M+SUf0T6k3XKt6FpZ9QlJI2inPV3I8B3UgHwSXeF0PfCIiJgCTgNNy/WYAiyJiPLAoz3eC04GlhfnPAxdGxB7Ak8D0filV7/oy8JOIeBOwN6m+HXU8JY0GPg5MjIi9SANZT6BzjudsYHJTWrtjeCQwPj9OBS7pozL2htm8tp4Lgb0i4q3A/wFnAeTvpROAt+R1Ls7fz3Uwm9fWE0ljgcOBhwvJlRzPQR3IKVziNSJeABqXeO0IEfFIRPwyTz9N+tIfTarjnJxtDnBs/5Sw90gaA7wb+EaeF3AIcGXOUvt6StoeeCdwKUBEvBART9GBx5M0EHdLSUOBrYBH6JDjGRH/DaxpSm53DKcAcyNZDAyXtHPflHTTtKpnRPw0Itbn2cWka39AquflEfF8RDwAdJG+nwe8NscT4ELgH4HiQLRKjudgD+SD5hKvksYBbwNuAkZFxCN50aPAqH4qVm/6EulD83Ke3xF4qvCl0QnHdndgNfDNfArhG5K2psOOZ0SsBL5Iask8AqwFbqXzjmdRu2PYyd9RHwR+nKc7qp6SpgArI+KOpkWV1HOwB/JBQdI2wPeBMyJiXXFZpL8t1PqvC5KOBlZFxK39XZaKDQX2BS6JiLcBz9LUjd4hx3MEqeWyO7ALsDUtui47VSccw55I+hTp1N9l/V2W3iZpK+CTwD/11T4HeyAvdYnXOpO0OSmIXxYRP8jJjzW6c/Lzqv4qXy85EDhG0oOk0yOHkM4lD89ds9AZx3YFsCIibsrzV5ICe6cdz8OAByJidUS8CPyAdIw77XgWtTuGHfcdJekk4Gjg/fHK/587qZ5vJP0IvSN/J40Bfinp9VRUz8EeyDv6Eq/5PPGlwNKI+LfConnAtDw9Dbi6r8vWmyLirIgYExHjSMfw+oh4P3ADcFzO1gn1fBRYLmnPnHQo6Za9HXU8SV3qkyRtld/DjXp21PFs0u4YzgOm5tHOk4C1hS742pE0mXQK7JiIeK6waB5wgqQtJO1OGgx2c3+UcVNFxF0R8QcRMS5/J60A9s2f32qOZ0QM6gdwFGn05K+BT/V3eXq5bgeRuujuBG7Pj6NI548XAfcD1wE79HdZe7HOBwPX5Ok3kL4MuoDvAVv0d/l6oX77AEvyMf0hMKITjyfwaeBe4FfAt4AtOuV4At8hnft/MX/JT293DAGR/lnza+Au0kj+fq/DJtSzi3SOuPF99NVC/k/let4HHNnf5d+UejYtfxDYqcrj6Su7mZmZ1dhg71o3MzOrNQdyMzOzGnMgNzMzqzEHcjMzsxpzIDczM6sxB3KzAUbSMxVv/4x89alN3l/+3+91km6X9Be9U8LX7OOTVWzXrFM4kJsNPmeQbkTSG94GEBH7RMR3e2mbzRzIzbrhQG5WA5LeKOknkm6V9DNJb8rps/P9jX8haZmk43L6ZpIuzvd+XihpvqTjJH2cdP3yGyTdUNj++ZLukLRY0mtuuqJ0v+wf5nsoL5b0Vkl/AHwb+OPcIn9j0zofl3RPXufynLZ1vn/zzfnGL1Ny+kmSfpDreL+kL+T0C0h3Qbtd0mU57QN5/dslfa1xu0tJz7Sqh6RRSve+viM/3tHddsxqp7+viuOHH368+gE80yJtETA+Tx9AugwtpHshf4/0o3wC6ba8kC5lOj+nv550/+7j8rIHyVeayvMBvCdPfwE4u8X+/x04J08fAtyepw8mX0mvxTq/IV99DRien/8Z+EAjjXRVxa2Bk4BlwPbA64CHgLHNrwfwZuBHwOZ5/mJganf1AL5LumEQpHubb9/ddvzwo26Pxg0IzGyAynevewfwvXTpcSBdsrThhxHxMnBPoTV9EPC9nP5osfXdwgvANXn6VuBdLfIcBLwXICKul7SjpO16KPqdwGWSfki6nCzA4aQb3Px9nn8dsGueXhQRa3Od7wF249W3fIR03fX9gFvya7Elr9xgpF09DgGm5rK/BKyV9FfdbMesVhzIzQa+zUj34t6nzfLnC9Nqk6c7L0ZE41rNL9F73wvvBt4JvAf4lKQ/yuV7b0TcV8wo6QBeXY925RAwJyLOarFsQ+rR3XbMasXnyM0GuEj3kH9A0vsg3dVO0t49rPY/wHvzufJRpC7whqeBbTewGD8D3p/3fzDweDTd275I0makrvEbgDNJ3dnbAAuAv8l3NUPS20rs+0Wl2/FCOsVwXD4/3zh3v1sP6y8CPpLzD5G0/UZux2xAciA3G3i2krSi8Pg7UhCdLukO4G5gSg/b+D7pTkz3kAak/RJYm5fNBH7SQ3d7s3OB/STdCVzAK7fcbGcI8G1JdwG3ARdFxFPAZ4DNgTsl3Z3nezIz578sIu4BzgZ+msuyENi5h/VPB/4sl+VWYMJGbsdsQPLdz8w6lKRtIuIZSTuSbv95YKR7IptZB/E5crPOdY2k4cAw4DMO4madyS1yMzOzGvM5cjMzsxpzIDczM6sxB3IzM7MacyA3MzOrMQdyMzOzGnMgNzMzq7H/DxxD3UdZQ6ZpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max malayalam sentence length:  139\n",
            "Min malayalam sentence length:  5\n",
            "Mean malayalam sentence length:  72.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "I-cYgE_hHwta",
        "outputId": "fae16635-581d-4318-b24a-48c6dbc67c91"
      },
      "source": [
        "telugu['sentence_length'] = telugu['telugu_text'].str.len()\n",
        "df2 = telugu['sentence_length'].value_counts().rename_axis('length of sentence').reset_index(name='no of sentences')\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "sentLength = df2['length of sentence']\n",
        "noOfSent = df2['no of sentences']\n",
        "ax.bar(sentLength,noOfSent)\n",
        "plt.title('Sentence length - no of such sentences in TELUGU dataset')\n",
        "plt.xlabel('Length of sentence')\n",
        "plt.ylabel('no of sentences')\n",
        "plt.savefig('/content/drive/MyDrive/NLP/Project/Dataset/tel_sent_distr.png')\n",
        "plt.show()\n",
        "\n",
        "print(\"Max telugu sentence length: \",df2['length of sentence'].max())\n",
        "print(\"Min telugu sentence length: \",df2['length of sentence'].min())\n",
        "print(\"Mean telugu sentence length: \",df2['length of sentence'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max telugu sentence length:  125\n",
            "Min telugu sentence length:  5\n",
            "Mean telugu sentence length:  65.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkYJsjHebxss"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rpm1T36SKLv"
      },
      "source": [
        "## Clean Pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlctbW7IBE4Q"
      },
      "source": [
        "def save_clean_data(sentences, filename):\n",
        "    dump(sentences, open(filename, 'wb'))\n",
        "    print('Saved: %s' % filename)\n",
        "\n",
        "def load_clean_sentences(filename):\n",
        "    return load(open(filename, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV-3y5cqb8l7"
      },
      "source": [
        "# Converted Pre-Processed dataset to 'pickel file'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "F4Sdnz2Ww1Q1",
        "outputId": "834fe068-a92f-44c5-ec82-fb43c25781c9"
      },
      "source": [
        "def load_doc(filename):\n",
        "    #file = open(filename, mode='rt', encoding='utf-8')\n",
        "    file = open(filename, mode='rt',encoding='utf-8')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "def to_pairs(mal_text, tel_text):\n",
        "    #malayalam_lines = mal_text[:].strip().split('\\n')\n",
        "    #telugu_lines = telugu_lines[:].strip().split('\\n')\n",
        "    pairs = []\n",
        "    for i in range(len(tel_text)):\n",
        "        pairs.append([])\n",
        "        pairs[i].append(pre_process_malayalam_sentence(mal_text[i]))\n",
        "        pairs[i].append(pre_process_telugu_sentence(tel_text[i]))\n",
        "    return pairs\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.replace(u',','')\n",
        "    text = text.replace(u'\"','')\n",
        "    text = text.replace(u'\"','')\n",
        "    text = text.replace(u\"‘‘\",'')\n",
        "    text = text.replace(u\"’’\",'')\n",
        "    text = text.replace(u\"''\",'')\n",
        "    text = text.replace(u\"।\",'')\n",
        "    text=text.replace(u',','')\n",
        "    text=text.replace(u'\"','')\n",
        "    text=text.replace(u'(','')\n",
        "    text=text.replace(u')','')\n",
        "    text=text.replace(u'\"','')\n",
        "    text=text.replace(u':','')\n",
        "    text=text.replace(u\"'\",'')\n",
        "    text=text.replace(u\"‘‘\",'')\n",
        "    text=text.replace(u\"’’\",'')\n",
        "    text=text.replace(u\"''\",'')\n",
        "    text=text.replace(u\".\",'')\n",
        "    text=text.replace(u\"-\",'')\n",
        "    text=text.replace(u\"।\",'')\n",
        "    text=text.replace(u\"?\",'')\n",
        "    text=text.replace(u\"\\\\\",'')\n",
        "    text=text.replace(u\"_\",'')\n",
        "    text=text.replace(\"'\", \"\")\n",
        "    text=text.replace('\"', \"\")\n",
        "    text= re.sub(\"'\", '', text)\n",
        "    text=re.sub('[0-9+\\-*/.%]', '', text)\n",
        "    text=text.strip()\n",
        "    text=re.sub(' +', ' ',text)\n",
        "    exclude = set(string.punctuation)\n",
        "    text= ''.join(ch for ch in text if ch not in exclude)\n",
        "    return text\n",
        "\n",
        "def pre_process_malayalam_sentence(line):\n",
        "    line=re.sub('[a-zA-Z]', '', line)\n",
        "    line = clean_text(line)\n",
        "    remove_nuktas = False\n",
        "    factory = IndicNormalizerFactory()\n",
        "    normalizer = factory.get_normalizer(\"ml\")\n",
        "    line = normalizer.normalize(line)\n",
        "    tokens = list()\n",
        "    for t in indic_tokenize.trivial_tokenize(line):\n",
        "        tokens.append(t)\n",
        "    line = tokens\n",
        "    line = [word for word in line if not re.search(r'\\d', word)]\n",
        "    line = ' '.join(line)\n",
        "    line = '<start> '+ line + ' <end>'\n",
        "    return (line)\n",
        "\n",
        "def pre_process_telugu_sentence(line):\n",
        "    line=re.sub('[a-zA-Z]', '', line)\n",
        "    line = clean_text(line)\n",
        "    remove_nuktas = False\n",
        "    factory = IndicNormalizerFactory()\n",
        "    normalizer = factory.get_normalizer(\"te\")\n",
        "    line = normalizer.normalize(line)\n",
        "    tokens = list()\n",
        "    for t in indic_tokenize.trivial_tokenize(line):\n",
        "        tokens.append(t)\n",
        "    line = tokens\n",
        "    line = [word for word in line if not re.search(r'\\d', word)]\n",
        "    line = ' '.join(line)\n",
        "    line = '<start> '+ line + ' <end>'\n",
        "    return (line)\n",
        "\n",
        "#malayalam_text = load_doc('/content/drive/MyDrive/NLP/Project/Dataset/malayalam.pkl')\n",
        "#telugu_text = load_doc('/content/drive/MyDrive/NLP/Project/Dataset/telugu.pkl')\n",
        "\"\"\"-----------Commented out as dataset is already prepared and saved as 'pkl' file in drive-------------------------\"\"\"\n",
        "\"\"\"pairs = to_pairs(np.array(df_malayalam), np.array(df_telugu))\n",
        "clean_pairs = np.array(pairs)\n",
        "save_clean_data(clean_pairs, '/content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu.pkl')\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"pairs = to_pairs(np.array(df_malayalam), np.array(df_telugu))\\nclean_pairs = np.array(pairs)\\nsave_clean_data(clean_pairs, '/content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu.pkl')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO_q-uKKQj6D",
        "outputId": "7b20df45-93f4-41ce-d0cc-e54521b10913"
      },
      "source": [
        "line = 'ഷെയ്ൻ തന്റെ ഇൻസ്റ്റ ഗ്രാം പേജിലൂടെയാണ് ചിത്രം പങ്കുവച്ചിരിക്കുന്നത് '\n",
        "line2 = 'ఈ విషయన్ని స్వయంగా ఆమె తెలిపింది'\n",
        "pairs = to_pairs([line],[line2])\n",
        "\"\"\"line=re.sub('[a-zA-Z]', '', line)\n",
        "line = clean_text(line)\n",
        "factory = IndicNormalizerFactory()\n",
        "normalizer = factory.get_normalizer(\"ml\")\n",
        "line = normalizer.normalize(line)\n",
        "tokens = list()\n",
        "for t in indic_tokenize.trivial_tokenize(line):\n",
        "    tokens.append(t)\n",
        "line = tokens\"\"\"\n",
        "pairs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<start> ഷെയ്ൻ തന്റെ ഇൻസ്റ്റ ഗ്രാം പേജിലൂടെയാണ് ചിത്രം പങ്കുവച്ചിരിക്കുന്നത് <end>',\n",
              "  '<start> ఈ విషయన్ని స్వయంగా ఆమె తెలిపింది <end>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AevO4qocGJM"
      },
      "source": [
        "# Loading data from 'pickel' file and and taking 50k entries from the dataset and splitting 40k as train data and 10k as test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGjDCnOgdWxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592f0efa-f31c-4f18-fe02-fe7c9513e04a"
      },
      "source": [
        "\"\"\"-----------Commented out as dataset is already prepared and saved as 'pkl' file in drive-------------------------\"\"\"\n",
        "\"\"\"# load dataset\n",
        "raw_dataset = load_clean_sentences('/content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu.pkl')\n",
        "\n",
        "n_sentences = 50000\n",
        "n_train = 40000\n",
        "#n_train = (int)(n_sentences/2 + 0.2*(n_sentences/2))\n",
        "dataset = raw_dataset[:n_sentences, :]\n",
        "\n",
        "train, test = dataset[:n_train], dataset[n_train:]\n",
        "\n",
        "save_clean_data(dataset, '/content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu-both.pkl')\n",
        "save_clean_data(train, '/content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu-train.pkl')\n",
        "save_clean_data(test, '/content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu-test.pkl')\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu-both.pkl\n",
            "Saved: /content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu-train.pkl\n",
            "Saved: /content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu-test.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBNkwccFchHs"
      },
      "source": [
        "# Loading train & test data from pickel file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTgBQ00qwjY"
      },
      "source": [
        "# load datasets\n",
        "dataset = load_clean_sentences('/content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu-both.pkl')\n",
        "train = load_clean_sentences('/content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu-train.pkl')\n",
        "test = load_clean_sentences('/content/drive/MyDrive/NLP/Project/Dataset/clean_malayalam-telugu-test.pkl')\n",
        "\n",
        "shuffle(dataset)\n",
        "shuffle(train)\n",
        "shuffle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNBQro2CTfSZ",
        "outputId": "3d86215e-f9c5-441d-88a6-af287785054c"
      },
      "source": [
        "lang = 'അവർ അതെല്ലാം ആസ്വദിക്കുകയാണ്'\n",
        "vocab = set()\n",
        "for phrase in lang:\n",
        "  vocab.update(phrase.split(' '))\n",
        "\n",
        "vocab = sorted(vocab)\n",
        "for index, word in enumerate(vocab):\n",
        "  print(index,word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 \n",
            "1 ം\n",
            "2 അ\n",
            "3 ആ\n",
            "4 ക\n",
            "5 ണ\n",
            "6 ത\n",
            "7 ദ\n",
            "8 യ\n",
            "9 ല\n",
            "10 വ\n",
            "11 സ\n",
            "12 ാ\n",
            "13 ി\n",
            "14 ു\n",
            "15 െ\n",
            "16 ്\n",
            "17 ർ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSt90bvNT7mk"
      },
      "source": [
        "class LanguageIndex():\n",
        "  def __init__(self, lang):\n",
        "    self.lang = lang\n",
        "    self.word2idx = {}\n",
        "    self.idx2word = {}\n",
        "    self.vocab = set()\n",
        "    \n",
        "    self.create_index()\n",
        "    \n",
        "  def create_index(self):\n",
        "    for phrase in self.lang:\n",
        "      self.vocab.update(phrase.split(' '))\n",
        "    \n",
        "    self.vocab = sorted(self.vocab)\n",
        "    \n",
        "    self.word2idx['<pad>'] = 0\n",
        "    for index, word in enumerate(self.vocab):\n",
        "      self.word2idx[word] = index + 1\n",
        "    \n",
        "    for word, index in self.word2idx.items():\n",
        "      self.idx2word[index] = word\n",
        "\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o36h0fLFj73L"
      },
      "source": [
        "def load_dataset(pairs):  \n",
        "    inp_lang = LanguageIndex(ml for ml, te in pairs)\n",
        "    targ_lang = LanguageIndex(te for ml, te in pairs)\n",
        "    input_tensor = [[inp_lang.word2idx[s] for s in ml.split(' ')] for ml, te in pairs]\n",
        "    target_tensor = [[targ_lang.word2idx[s] for s in te.split(' ')] for ml, te in pairs]\n",
        "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "    return inp_lang, targ_lang, max_length_inp, max_length_tar\n",
        "\n",
        "inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x27lwXkFzkMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b41907f-9ece-455d-a755-7cec3cc2b626"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "def train_tensor(pairs, max_length_inp, max_length_tar, inp_lang, targ_lang):\n",
        "    input_tensor_x = [[inp_lang.word2idx[s] for s in ml.split(' ')] for ml, te in pairs]\n",
        "    print(input_tensor_x[0])\n",
        "    target_tensor_y = [[targ_lang.word2idx[s] for s in te.split(' ')] for ml, te in pairs]\n",
        "    input_tensor_x = tf.keras.preprocessing.sequence.pad_sequences(input_tensor_x, maxlen=max_length_inp, padding='post')\n",
        "    target_tensor_y = tf.keras.preprocessing.sequence.pad_sequences(target_tensor_y, maxlen=max_length_tar, padding='post')\n",
        "    return input_tensor_x, target_tensor_y\n",
        "\n",
        "input_tensor_train, target_tensor_train = train_tensor(train, max_length_inp, max_length_targ, inp_lang, targ_lang)\n",
        "input_tensor_val, target_tensor_val = train_tensor(test, max_length_inp, max_length_targ, inp_lang, targ_lang)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6, 8257, 44308, 56211, 5]\n",
            "[6, 4750, 1512, 7284, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBJNpRxV0QG1",
        "outputId": "a47a5365-8ecb-4113-a94e-02c74d5fe693"
      },
      "source": [
        "len(input_tensor_train[0]), len(target_tensor_train[0]), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33, 27, 10000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO0OSpSzWmt_",
        "outputId": "990903bd-a018-421a-fa71-c891f8d32dc0"
      },
      "source": [
        "input_tensor_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    6,  8257, 44308, 56211,     5,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl52BFcd0jTJ",
        "outputId": "98f10551-e8c7-4b81-ed77-f8e0257428f1"
      },
      "source": [
        "tf.config.experimental_connect_to_host('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.72.92.114:8470\n",
            "INFO:tensorflow:Clearing out eager caches\n",
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq2zjCLm0VT_"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 300\n",
        "units = 500\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi2mtCpGoL2u",
        "outputId": "074bb83f-d1f1-406b-ea41-e5ed54307fab"
      },
      "source": [
        "len(inp_lang.word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLD7lIi83Wfe"
      },
      "source": [
        "def gru(units):\n",
        "    if tf.test.is_gpu_available():\n",
        "        #print(\"Using GPU\")\n",
        "        return tf.compat.v1.keras.layers.CuDNNGRU(units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "    else:\n",
        "        #print(\"Using TPU\")\n",
        "        return tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeFP9oi13h8D"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding( vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoFMBJn73mlC"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.FullyConnected = tf.keras.layers.Dense(vocab_size)\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.gru(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.FullyConnected(output)\n",
        "        return x, state, attention_weights\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RNwLm23qVC",
        "outputId": "8d28f7f4-b30a-4b28-84d2-1331909ebd75"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-49-2cf59a4b2acd>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "here\n",
            "here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXje5UeX3vBw"
      },
      "source": [
        "optimizer = tf.optimizers.Adam()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = 1 - np.equal(real, 0)\n",
        "  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ornBCGEo33SO"
      },
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/NLP/Project/Model/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder,decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YybKra-M4NvA",
        "outputId": "713289fb-3c70-4269-9e5c-e9030236bf68"
      },
      "source": [
        "EPOCHS = 4\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ)) in enumerate(dataset):\n",
        "        #print (batch)\n",
        "        #print (inp, targ)\n",
        "        loss = 0\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(inp, hidden)\n",
        "            \n",
        "            dec_hidden = enc_hidden\n",
        "            \n",
        "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       \n",
        "            \n",
        "                     # Teacher forcing\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "                loss += loss_function(targ[:, t], predictions)\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "        \n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables\n",
        "        \n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,batch,batch_loss.numpy()))\n",
        "    # saving (checkpoint) the model every 2 epochs\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.0739\n",
            "Epoch 1 Batch 100 Loss 2.1453\n",
            "Epoch 1 Batch 200 Loss 2.1653\n",
            "Epoch 1 Batch 300 Loss 1.8031\n",
            "Epoch 1 Batch 400 Loss 2.0041\n",
            "Epoch 1 Batch 500 Loss 1.9363\n",
            "Epoch 1 Batch 600 Loss 1.5938\n",
            "Epoch 1 Loss 1.8733\n",
            "Time taken for 1 epoch 2038.2663867473602 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.8130\n",
            "Epoch 2 Batch 100 Loss 1.5078\n",
            "Epoch 2 Batch 200 Loss 1.8111\n",
            "Epoch 2 Batch 300 Loss 1.6350\n",
            "Epoch 2 Batch 400 Loss 1.4662\n",
            "Epoch 2 Batch 500 Loss 1.6257\n",
            "Epoch 2 Batch 600 Loss 1.6864\n",
            "Epoch 2 Loss 1.6822\n",
            "Time taken for 1 epoch 2049.64165186882 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.4658\n",
            "Epoch 3 Batch 100 Loss 1.1732\n",
            "Epoch 3 Batch 200 Loss 1.4507\n",
            "Epoch 3 Batch 300 Loss 1.3237\n",
            "Epoch 3 Batch 400 Loss 1.4070\n",
            "Epoch 3 Batch 500 Loss 1.4441\n",
            "Epoch 3 Batch 600 Loss 1.4176\n",
            "Epoch 3 Loss 1.4619\n",
            "Time taken for 1 epoch 2042.216349363327 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.1850\n",
            "Epoch 4 Batch 100 Loss 1.1888\n",
            "Epoch 4 Batch 200 Loss 1.1671\n",
            "Epoch 4 Batch 300 Loss 1.2325\n",
            "Epoch 4 Batch 400 Loss 1.3159\n",
            "Epoch 4 Batch 500 Loss 1.2282\n",
            "Epoch 4 Batch 600 Loss 1.2320\n",
            "Epoch 4 Loss 1.2162\n",
            "Time taken for 1 epoch 2036.779406785965 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF695oSEiGdU"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_J1z2utPhKb"
      },
      "source": [
        "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    \n",
        "    #sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.idx2word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1tMTVd4iNUa"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    \n",
        "    fontdict = {'fontsize': 14}\n",
        "    \n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX86ov1DiPJk"
      },
      "source": [
        "def translate(sentence, tel_sen , encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ, sample,counter):\n",
        "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "    if (counter%100 ==0):\n",
        "      print('Input: {}'.format(sentence), file = sample)\n",
        "      print('Actual_translation: {}'.format(tel_sen), file = sample)\n",
        "      print('Predicted translation: {}'.format(result), file = sample)\n",
        "      print (\"\", file=sample)\n",
        "    \n",
        "    #attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    #plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vcu3wZliS9l",
        "outputId": "eb8d953d-4dc1-45ad-c3d1-e4b7173c620e"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint_dir = '/content/drive/MyDrive/NLP/Project/Model/training_checkpoints'\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7effa63f9990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKmKLSTriWRp",
        "outputId": "b60978f2-7d9d-4205-af35-d4fe303b6859"
      },
      "source": [
        "actual, predicted = list(), list()\n",
        "\n",
        "sample = open('/content/drive/MyDrive/NLP/Project/Evaluation Results/training_result.txt', 'w')\n",
        "\n",
        "for ml, te in train:\n",
        "    predicted_sen = translate(ml, te, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ, sample)\n",
        "    telugu_list = te.split()\n",
        "    predicted_sen = predicted_sen.split()\n",
        "    if (telugu_list[-1] == \"<end>\"):\n",
        "        telugu_list = telugu_list[:-1]\n",
        "    if (telugu_list[0] == \"<start>\"):\n",
        "        telugu_list.pop(0)\n",
        "    if (predicted_sen[-1] == \"<end>\"):\n",
        "        predicted_sen = predicted_sen[:-1]\n",
        "    actual.append(telugu_list)\n",
        "    predicted.append(predicted_sen)\n",
        "\n",
        "print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "\n",
        "# n-gram individual BLEU\n",
        "print('Individual 1-gram: %f' % corpus_bleu(actual, predicted, weights=(1, 0, 0, 0)))\n",
        "print('Individual 2-gram: %f' % corpus_bleu(actual, predicted, weights=(0, 1, 0, 0)))\n",
        "print('Individual 3-gram: %f' % corpus_bleu(actual, predicted, weights=(0, 0, 1, 0)))\n",
        "print('Individual 4-gram: %f' % corpus_bleu(actual, predicted, weights=(0, 0, 0, 1)))\n",
        "\n",
        "sample.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.018905\n",
            "BLEU-2: 0.137495\n",
            "BLEU-3: 0.269942\n",
            "BLEU-4: 0.370804\n",
            "Individual 1-gram: 0.018905\n",
            "Individual 2-gram: 1.000000\n",
            "Individual 3-gram: 1.000000\n",
            "Individual 4-gram: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGSYP8XQibbK",
        "outputId": "d96f6357-5af6-42c7-c361-6e4c6d2db1ff"
      },
      "source": [
        "actual, predicted = list(), list()\n",
        "\n",
        "sample = open('/content/drive/MyDrive/NLP/Project/Evaluation Results/testing_result.txt', 'w') \n",
        "counter = 1\n",
        "for ml, te in test:\n",
        "    predicted_sen = translate(ml, te, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ, sample,counter)\n",
        "    telugu_list = te.split()\n",
        "    predicted_sen = predicted_sen.split()\n",
        "    if (telugu_list[-1] == \"<end>\"):\n",
        "        telugu_list = telugu_list[:-1]\n",
        "    if (telugu_list[0] == \"<start>\"):\n",
        "        telugu_list.pop(0)\n",
        "    if (predicted_sen[-1] == \"<end>\"):\n",
        "        predicted_sen = predicted_sen[:-1]\n",
        "    actual.append(telugu_list)\n",
        "    predicted.append(predicted_sen)\n",
        "    if (counter%100 == 0):\n",
        "      print(\"{0} % completed!\".format(round((counter/(len(test))*100),2)))\n",
        "    counter += 1\n",
        "\n",
        "print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "\n",
        "# n-gram individual BLEU\n",
        "print('Individual 1-gram: %f' % corpus_bleu(actual, predicted, weights=(1, 0, 0, 0)))\n",
        "print('Individual 2-gram: %f' % corpus_bleu(actual, predicted, weights=(0, 1, 0, 0)))\n",
        "print('Individual 3-gram: %f' % corpus_bleu(actual, predicted, weights=(0, 0, 1, 0)))\n",
        "print('Individual 4-gram: %f' % corpus_bleu(actual, predicted, weights=(0, 0, 0, 1)))\n",
        "\n",
        "sample.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0 % completed!\n",
            "2.0 % completed!\n",
            "3.0 % completed!\n",
            "4.0 % completed!\n",
            "5.0 % completed!\n",
            "6.0 % completed!\n",
            "7.0 % completed!\n",
            "8.0 % completed!\n",
            "9.0 % completed!\n",
            "10.0 % completed!\n",
            "11.0 % completed!\n",
            "12.0 % completed!\n",
            "13.0 % completed!\n",
            "14.0 % completed!\n",
            "15.0 % completed!\n",
            "16.0 % completed!\n",
            "17.0 % completed!\n",
            "18.0 % completed!\n",
            "19.0 % completed!\n",
            "20.0 % completed!\n",
            "21.0 % completed!\n",
            "22.0 % completed!\n",
            "23.0 % completed!\n",
            "24.0 % completed!\n",
            "25.0 % completed!\n",
            "26.0 % completed!\n",
            "27.0 % completed!\n",
            "28.0 % completed!\n",
            "29.0 % completed!\n",
            "30.0 % completed!\n",
            "31.0 % completed!\n",
            "32.0 % completed!\n",
            "33.0 % completed!\n",
            "34.0 % completed!\n",
            "35.0 % completed!\n",
            "36.0 % completed!\n",
            "37.0 % completed!\n",
            "38.0 % completed!\n",
            "39.0 % completed!\n",
            "40.0 % completed!\n",
            "41.0 % completed!\n",
            "42.0 % completed!\n",
            "43.0 % completed!\n",
            "44.0 % completed!\n",
            "45.0 % completed!\n",
            "46.0 % completed!\n",
            "47.0 % completed!\n",
            "48.0 % completed!\n",
            "49.0 % completed!\n",
            "50.0 % completed!\n",
            "51.0 % completed!\n",
            "52.0 % completed!\n",
            "53.0 % completed!\n",
            "54.0 % completed!\n",
            "55.0 % completed!\n",
            "56.0 % completed!\n",
            "57.0 % completed!\n",
            "58.0 % completed!\n",
            "59.0 % completed!\n",
            "60.0 % completed!\n",
            "61.0 % completed!\n",
            "62.0 % completed!\n",
            "63.0 % completed!\n",
            "64.0 % completed!\n",
            "65.0 % completed!\n",
            "66.0 % completed!\n",
            "67.0 % completed!\n",
            "68.0 % completed!\n",
            "69.0 % completed!\n",
            "70.0 % completed!\n",
            "71.0 % completed!\n",
            "72.0 % completed!\n",
            "73.0 % completed!\n",
            "74.0 % completed!\n",
            "75.0 % completed!\n",
            "76.0 % completed!\n",
            "77.0 % completed!\n",
            "78.0 % completed!\n",
            "79.0 % completed!\n",
            "80.0 % completed!\n",
            "81.0 % completed!\n",
            "82.0 % completed!\n",
            "83.0 % completed!\n",
            "84.0 % completed!\n",
            "85.0 % completed!\n",
            "86.0 % completed!\n",
            "87.0 % completed!\n",
            "88.0 % completed!\n",
            "89.0 % completed!\n",
            "90.0 % completed!\n",
            "91.0 % completed!\n",
            "92.0 % completed!\n",
            "93.0 % completed!\n",
            "94.0 % completed!\n",
            "95.0 % completed!\n",
            "96.0 % completed!\n",
            "97.0 % completed!\n",
            "98.0 % completed!\n",
            "99.0 % completed!\n",
            "100.0 % completed!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.016567\n",
            "BLEU-2: 0.128712\n",
            "BLEU-3: 0.258433\n",
            "BLEU-4: 0.358764\n",
            "Individual 1-gram: 0.016567\n",
            "Individual 2-gram: 1.000000\n",
            "Individual 3-gram: 1.000000\n",
            "Individual 4-gram: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaUpgSE83_RD"
      },
      "source": [
        "# Testing the model with some examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xKYolZlPnqS"
      },
      "source": [
        "def tst_translate(sentence, tel_sen , encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ,sample):\n",
        "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "    print('Input: {}'.format(sentence), file = sample)\n",
        "    print('Actual_translation: {}'.format(tel_sen), file = sample)\n",
        "    print('Predicted translation: {}'.format(result), file = sample)\n",
        "    print (\"\", file=sample)\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Actual_translation: {}'.format(tel_sen))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    print(\"\")\n",
        "    \n",
        "    #attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    #plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs9iN1P_4Cd9",
        "outputId": "2706c70b-e442-413c-a6f5-c419f90008df"
      },
      "source": [
        "tst_list = [['<start> റാസ പറഞ്ഞു <end>','<start> అని రోజా అన్నారు <end>'],\n",
        "            ['<start> ഞാൻ ഫ്ലൈറ്റിൽ കയറി <end>','<start> నేను పెరట్లోకి వెళ్ళాను <end>'],\n",
        "            ['<start> നന്ദ സ്വയം പറഞ്ഞു <end>','<start> ఈ విషయన్ని స్వయంగా ఆమె తెలిపింది <end>'],\n",
        "            ['<start> അതിനുള്ള യാത്രയാണിത്','<start> ఇది ఓ ప్రయాణం <end>'],\n",
        "            ['<start> കൂട്ടിലുണ്ടായിരുന്ന മറ്റൊരാടിന് ഗുരുതരമായി കടിയേറ്റിട്ടുണ്ട് <end>','<start> మరో అరుగురు తీవ్రంగా గాయపడ్డారు <end>'],\n",
        "            ['<start> ഷെയ്ൻ തന്റെ ഇൻസ്റ്റ ഗ്രാം പേജിലൂടെയാണ് ചിത്രം പങ്കുവച്ചിരിക്കുന്നത് <end>','<start> ఈ ఫోటోను బీసీసీఐ తన ఇన్స్టాగ్రామ్లో షేర్ చేసింది <end>'],\n",
        "            ['<start> ഭാവന ഉൾപ്പെടെ വിദ്യാർഥികൾക്ക് ൽ മാർക്ക് ലഭിച്ചു <end>','<start> మార్కులకుగానూ మంది విద్యార్థులకు మార్కులు వచ్చాయి <end>'],\n",
        "            ['<start> എനിക്ക് കാശ് കിട്ടുന്നു <end>','<start> నాది కొంచెం డబ్బుంది <end>'],\n",
        "            ['<start> ഇത്തരം അടിസ്ഥാന സവിശേഷതകൾ ഉണ്ട് <end>','<start> తయారీ యొక్క ప్రధాన లక్షణాలు ఉన్నాయి <end>'],\n",
        "            ['<start> ഞാൻ നടക്കുക ആണ് <end>','<start> నేను నడుస్తున్నాను <end>'],\n",
        "            ['<start> ചിത്രത്തിന് സെൻസർ ബോർഡ് യു സർട്ടിഫിക്കറ്റ് നൽകി <end>','<start> సినిమాను చూసిన సెన్సార్ వారు చిత్రానికి యు/ఏ సర్టిఫికెట్ జారీ చేసారు <end>'],\n",
        "            ['<start> എന്നാൽ ഈ സിനിമാ ആണ് <end>','<start> కానీ ఈ సినిమా <end>']]\n",
        "#['<start> മനുഷ്യരെല്ലാവരും തുല്യാവകാശങ്ങളോടും സ്വാതന്ത്ര്യത്തോടുംകൂടി ജനിച്ചിട്ടുള്ളവരാണ് <end>','<start> ప్రజలందరూ  సమాన హక్కు మరియు స్వతంత్రంతో పుట్టారు <end>'],\n",
        "\n",
        "tst_list = np.array(tst_list)\n",
        "tst_actual, tst_predicted = list(), list()\n",
        "\n",
        "sample_prediction = open('/content/drive/MyDrive/NLP/Project/Evaluation Results/sample_prediction_result.txt', 'w') \n",
        "counter = 1\n",
        "for ml, te in tst_list:\n",
        "    tst_predicted_sen = tst_translate(ml, te, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ,sample_prediction)\n",
        "    tst_telugu_list = te.split()\n",
        "    tst_predicted_sen = tst_predicted_sen.split()\n",
        "    if (tst_telugu_list[-1] == \"<end>\"):\n",
        "        tst_telugu_list = tst_telugu_list[:-1]\n",
        "    if (tst_telugu_list[0] == \"<start>\"):\n",
        "        tst_telugu_list.pop(0)\n",
        "    if (tst_predicted_sen[-1] == \"<end>\"):\n",
        "        tst_predicted_sen = tst_predicted_sen[:-1]\n",
        "    tst_actual.append(tst_telugu_list)\n",
        "    tst_predicted.append(tst_predicted_sen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> റാസ പറഞ്ഞു <end>\n",
            "Actual_translation: <start> అని రోజా అన్నారు <end>\n",
            "Predicted translation: కోదండ నవ్వుతూ <end> \n",
            "\n",
            "Input: <start> ഞാൻ ഫ്ലൈറ്റിൽ കയറി <end>\n",
            "Actual_translation: <start> నేను పెరట్లోకి వెళ్ళాను <end>\n",
            "Predicted translation: నేను నేను పెరట్లోకి వెళ్ళాను <end> \n",
            "\n",
            "Input: <start> നന്ദ സ്വയം പറഞ്ഞു <end>\n",
            "Actual_translation: <start> ఈ విషయన్ని స్వయంగా ఆమె తెలిపింది <end>\n",
            "Predicted translation: ఈ విషయాన్ని అతను చెప్పాడు <end> \n",
            "\n",
            "Input: <start> അതിനുള്ള യാത്രയാണിത്\n",
            "Actual_translation: <start> ఇది ఓ ప్రయాణం <end>\n",
            "Predicted translation: ఇది ఒక గొప్ప <end> \n",
            "\n",
            "Input: <start> കൂട്ടിലുണ്ടായിരുന്ന മറ്റൊരാടിന് ഗുരുതരമായി കടിയേറ്റിട്ടുണ്ട് <end>\n",
            "Actual_translation: <start> మరో అరుగురు తీవ్రంగా గాయపడ్డారు <end>\n",
            "Predicted translation: మరో మంది తీవ్రంగా గాయపడ్డారు <end> \n",
            "\n",
            "Input: <start> ഷെയ്ൻ തന്റെ ഇൻസ്റ്റ ഗ്രാം പേജിലൂടെയാണ് ചിത്രം പങ്കുവച്ചിരിക്കുന്നത് <end>\n",
            "Actual_translation: <start> ఈ ఫోటోను బీసీసీఐ తన ఇన్స్టాగ్రామ్లో షేర్ చేసింది <end>\n",
            "Predicted translation: ఈ విషయాన్ని తన ఇన్స్టాగ్రామ్లో షేర్ చేసింది <end> \n",
            "\n",
            "Input: <start> ഭാവന ഉൾപ്പെടെ വിദ്യാർഥികൾക്ക് ൽ മാർക്ക് ലഭിച്ചു <end>\n",
            "Actual_translation: <start> మార్కులకుగానూ మంది విద్యార్థులకు మార్కులు వచ్చాయి <end>\n",
            "Predicted translation: వేలాది మంది విద్యార్థులు మృతి <end> \n",
            "\n",
            "Input: <start> എനിക്ക് കാശ് കിട്ടുന്നു <end>\n",
            "Actual_translation: <start> నాది కొంచెం డబ్బుంది <end>\n",
            "Predicted translation: నాకు గదిలోనే ప్రేమిస్తాను <end> \n",
            "\n",
            "Input: <start> ഇത്തരം അടിസ്ഥാന സവിശേഷതകൾ ഉണ്ട് <end>\n",
            "Actual_translation: <start> తయారీ యొక్క ప్రధాన లక్షణాలు ఉన్నాయి <end>\n",
            "Predicted translation: ఇది ఒక చిన్న ప్రయోజనాలు <end> \n",
            "\n",
            "Input: <start> ഞാൻ നടക്കുക ആണ് <end>\n",
            "Actual_translation: <start> నేను నడుస్తున్నాను <end>\n",
            "Predicted translation: నేను ద్వేషిస్తున్నాను <end> \n",
            "\n",
            "Input: <start> ചിത്രത്തിന് സെൻസർ ബോർഡ് യു സർട്ടിഫിക്കറ്റ് നൽകി <end>\n",
            "Actual_translation: <start> సినిమాను చూసిన సెన్సార్ వారు చిత్రానికి యు/ఏ సర్టిఫికెట్ జారీ చేసారు <end>\n",
            "Predicted translation: ఈ చిత్రం లో తమిళ చిత్ర పరిశ్రమకు మధ్య సర్టిఫికెట్ జారీ చేసింది <end> \n",
            "\n",
            "Input: <start> എന്നാൽ ഈ സിനിമാ ആണ് <end>\n",
            "Actual_translation: <start> కానీ ఈ సినిమా <end>\n",
            "Predicted translation: కానీ ఈ సినిమా <end> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XJ1PGs2P7Gl",
        "outputId": "2929744b-ecf4-49ec-81b4-44c990c0fe2f"
      },
      "source": [
        "tst_mal_list = list(df_malayalam[100000:100010])\n",
        "tst_mal_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['മാർക്കറ്റ് ഷെയറും ഇതനുസരിച്ച് ഇടിഞ്ഞു.',\n",
              " 'ഗൗതം മേനോനാണ് ചിത്രത്തിന്റെ സംവിധായകന്\\u200d.',\n",
              " '’ റാസ പറഞ്ഞു.',\n",
              " 'ചിത്രത്തിന് സെൻസർ ബോർഡ് യു സർട്ടിഫിക്കറ്റ് നൽകി.',\n",
              " 'ഉൽപ്പന്ന തരംതിരിവ്',\n",
              " 'അവന്\\u200d പെട്ടെന്ന് പുറത്തേയ്ക്കിറങ്ങിപ്പോയി.',\n",
              " 'ഇതിനായി ഇവര്\\u200d പ്രത്യേകപരിശീലനത്തിന് വിധേയരാകണം.',\n",
              " 'എന്നാൽ ഇത് മത്സരിക്കേണ്ടതും ആവശ്യമാണ്.',\n",
              " 'ചൈനീസ് പ്രസിഡന്റ് ഷീ ജിംഗ് പിംഗും പാക് പ്രധാനമന്ത്രി ഇമ്രാന്\\u200d ഖാനും നടത്തിയ കൂടിക്കാഴ്ചയ്ക്ക് ശേഷമാണ് വാഗ്ദാനം ഉണ്ടായത്.',\n",
              " 'ആത്മവിശ്വാസവും വേണം.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LAkOnPPMEFx",
        "outputId": "8dfc9e8e-2500-46ee-fade-a2bedf9a2d16"
      },
      "source": [
        "tst_tel_list = list(df_telugu[100000:100010])\n",
        "tst_tel_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ఫలితంగానే స్టాక్ మార్కెట్లు నష్టాలను చవిచూస్తున్నాయి.',\n",
              " 'ఈ సినిమా దర్శకుడు గౌతం మీనన్ కావడం… ప్రధాన ఆకర్షణ.',\n",
              " 'అని రోజా అన్నారు.',\n",
              " 'సినిమాను చూసిన సెన్సార్ వారు చిత్రానికి యు/ఏ సర్టిఫికెట్ జారీ చేసారు.',\n",
              " 'ఉత్పత్తి వర్గీకరణ',\n",
              " 'వెంట\\u200cనే అవుట్ అయ్యాడు.',\n",
              " 'ఈ దూరానికి ప్రత్యేక శిక్షణ అవసరం.',\n",
              " 'కానీ పోటీల్లో అది తప్పనిసరి.',\n",
              " 'పాకిస్థాన్ ప్రధాని ఇమ్రాన్\\u200c ఖాన్\\u200c, చైనా అధ్యక్షుడు జిన్\\u200cపింగ్ సమావేశమైన మరుసటి రోజునే బీజింగ్\\u200c నుంచి ఈ ప్రకటన రావడం విశేషం.',\n",
              " 'ఆత్మవిశ్వాసంతో మెలగాల్సి ఉంటుంది.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}